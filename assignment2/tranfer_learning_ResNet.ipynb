{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6OysHDD8aJ85"
      },
      "outputs": [],
      "source": [
        "from torch import nn , save , load\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhrJP3ciaJ87",
        "outputId": "5ac94709-ecb2-4ede-d5ce-42deb66501a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Checking if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HokP_tDGaJ88",
        "outputId": "72cbf8b9-ffac-4f77-ca77-3e40440fdc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: dataTrain\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=4)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ColorJitter(brightness=(0.8, 1.2), contrast=None, saturation=None, hue=None)\n",
            "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )\n",
            "-----\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: dataTest\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),         # Random crop with padding\n",
        "    transforms.RandomHorizontalFlip(),            # Random horizontal flip\n",
        "    transforms.ColorJitter(brightness=0.2),       # Random color jitter\n",
        "    transforms.RandomRotation(10),                # Random rotation (degrees)\n",
        "    transforms.ToTensor(),                        # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "])\n",
        "\n",
        "# For test dataset, only normalization is applied\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "CIFAR_train = datasets.CIFAR10('dataTrain', train=True, download=True,transform=transform_train)\n",
        "\n",
        "CIFAR_test = datasets.CIFAR10('dataTest', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "print(CIFAR_train)\n",
        "print('-----')\n",
        "print(CIFAR_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "URXvIPRFaJ89"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1).to(device)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mRES1.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\". "
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('RES1.ckpt'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x2xKEEwAaJ89"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.requires_grads = True\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=CIFAR_train,batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=CIFAR_test,batch_size=batch_size,shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMyGlbN_aJ8-"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 10),\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "cf66a30852a840a398fcf195cddae089",
            "99263f283d5f47618aa22e5200a3d8ce",
            "6975afa1dbcb47d9b7ad88684e2d3b1d",
            "59dc0af916824ae4a161ec4e42cab468",
            "a951b6b7cb854e41b305785f0726dfeb",
            "ae141b632f3b4505a543f661a10867db",
            "9b30323afbce41b6bdad4748d2eb3f73",
            "c15fbdd1fc0a40d7ae635c9f91b62fcf",
            "eabc07f1a1dd4aa492251afdff00fa27",
            "f70882b366404ca090d54f2310fe2fed",
            "5b3b9a2f61074cc4bd2a7a646e9e92e5",
            "88620bd06b164cea9dd554922d439ae3",
            "d97b6e35c7a24eb8adffe8c8efc6fcbe",
            "c33ce3f4a5ba4e9e90e5b7e3c36ca935",
            "07b6806e28c549df9652772787d63bb6",
            "8d0d136d84e14c7daa30a7801269ea02",
            "fad646b275aa45608bbed6fe79905d92",
            "0eb52f347ec24f23ba519b19da81da5e",
            "bb8fce8c79014b7ca09f5cc50c2e82ba",
            "266f11acc2724567ab35bfe13307c2f4",
            "4268d00389904d9c822d0832f0c5607a",
            "64ba3e220d374b04b79259e17e42b8d0",
            "cce250deb0434c248a8202d14f39d34b",
            "d62a54d17044461db3c59fb13ca39230",
            "610de0b8f730433ea316013983396de5",
            "6e43ac91331247a7933d11628b4d0c02",
            "251b51a7534a47b99c7c32d6f6e0be69",
            "a018f3a29068407eab8764abcd8bdf6c",
            "50503da1d6274038b016f5c5a98dc4d8",
            "3fae71c1f57c4ee28a3a274c1cc350cf"
          ]
        },
        "id": "8qhJpcyzaJ8-",
        "outputId": "f51a5642-ef55-4811-c394-582008f80c57"
      },
      "outputs": [],
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    for i, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        # optimizer.require_grad = True\n",
        "\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WQeqrUsMhmun"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EggE6esZaJ8-"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'RES2.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'collections.OrderedDict'>\n"
          ]
        }
      ],
      "source": [
        "model = torch.load('RES1.ckpt')\n",
        "print(type(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qFGMij5GaJ8-"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     17\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{\u001b[39;00mnum_correct\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m with accuracy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mfloat\u001b[39m(num_correct)\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mfloat\u001b[39m(num_samples)\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m         )\n\u001b[1;32m     21\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 23\u001b[0m check_accuracy(train_loader, model)\n",
            "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mcheck_accuracy\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m num_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m num_samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49meval()\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m loader:\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ],
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} from {num_samples} with accuracy\"\n",
        "            f\" {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
        "        )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "check_accuracy(train_loader, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bL5N0EBuaJ8_"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'collections.OrderedDict' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m   labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[39m#   inputs = inputs.reshape(inputs.shape[0], -1)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m   output \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     19\u001b[0m   output \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mexp(output), \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     20\u001b[0m   y_pred\u001b[39m.\u001b[39mextend(output) \u001b[39m# Save Prediction\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "with torch.no_grad():\n",
        "\n",
        "  for inputs, labels in test_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "        #   inputs = inputs.reshape(inputs.shape[0], -1)\n",
        "\n",
        "          output = model(inputs)\n",
        "\n",
        "          output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "          y_pred.extend(output) # Save Prediction\n",
        "\n",
        "          labels = labels.data.cpu().numpy()\n",
        "          y_true.extend(labels) # Save Truth\n",
        "\n",
        "  # constant for classes\n",
        "  classes = ('Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "        'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYVdZL0_aJ8_"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score, accuracy_score, precision_score, recall_score, confusion_matrix , classification_report\n\u001b[0;32m----> 2\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(y_pred,y_true) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      3\u001b[0m report\u001b[39m=\u001b[39mclassification_report(y_true, y_pred,target_names \u001b[39m=\u001b[39m classes)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix , classification_report\n",
        "acc = accuracy_score(y_pred,y_true) * 100\n",
        "report=classification_report(y_true, y_pred,target_names = classes)\n",
        "print(f\"Accuracy = {acc:.2f}%\")\n",
        "print(\"Classification Report: \\n\",report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NP-lOu7aJ8_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
